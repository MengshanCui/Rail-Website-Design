import os
import json
import base64
from email import message_from_bytes
from bs4 import BeautifulSoup  # ç”¨äºè§£æ HTML

def parse_mhtml_to_json(mhtml_file, output_json):
    """
    è§£æ .mhtml æ–‡ä»¶å¹¶å°†å…¶å†…å®¹æŒ‰æ ‡é¢˜å±‚çº§åˆ†ç»„ä¸º JSON æ ¼å¼
    """
    try:
        # è¯»å– .mhtml æ–‡ä»¶
        with open(mhtml_file, "rb") as f:
            mhtml_content = f.read()

        # ä½¿ç”¨ email æ¨¡å—è§£æ .mhtml æ–‡ä»¶
        msg = message_from_bytes(mhtml_content)

        # æå– HTML å’Œèµ„æº
        html_content = None
        resources = {}

        for part in msg.walk():
            content_type = part.get_content_type()
            content_disposition = part.get("Content-Disposition", "")

            # æå– HTML å†…å®¹
            if content_type == "text/html" and html_content is None:
                html_content = part.get_payload(decode=True).decode("utf-8")

            # æå–èµ„æºæ–‡ä»¶ï¼ˆå¦‚å›¾ç‰‡ã€CSSã€JSï¼‰
            elif "attachment" in content_disposition:
                filename = part.get_param("filename", header="Content-Disposition")
                if filename:
                    resources[filename] = base64.b64encode(part.get_payload(decode=True)).decode("utf-8")

        # ä½¿ç”¨ BeautifulSoup è§£æ HTML å†…å®¹
        soup = BeautifulSoup(html_content, "html.parser")

        # æŒ‰æ ‡é¢˜å±‚çº§åˆ†ç»„å†…å®¹
        def parse_sections(tags):
            stack = []  # ç”¨äºå­˜å‚¨æ ‡é¢˜å±‚çº§
            sections = []  # æœ€ç»ˆçš„åˆ†ç»„ç»“æœ

            for tag in tags:
                tag_name = tag.name
                if tag_name in ["h1", "h2", "h3", "h4", "h5", "h6"]:
                    # åˆ›å»ºæ–°çš„æ ‡é¢˜èŠ‚ç‚¹
                    new_section = {"title": tag.get_text(strip=True), "content": []}
                    level = int(tag_name[1])  # è·å–æ ‡é¢˜çº§åˆ«ï¼ˆ1-6ï¼‰

                    # å°†æ–°æ ‡é¢˜æ’å…¥åˆ°æ­£ç¡®çš„å±‚çº§
                    while stack and stack[-1]["level"] >= level:
                        stack.pop()  # å¼¹å‡ºæ¯”å½“å‰çº§åˆ«é«˜æˆ–ç›¸åŒçš„æ ‡é¢˜

                    if stack:
                        stack[-1]["section"]["content"].append(new_section)
                    else:
                        sections.append(new_section)

                    # å°†æ–°æ ‡é¢˜å‹å…¥å †æ ˆ
                    stack.append({"level": level, "section": new_section})
                elif tag_name == "p":
                    # å¤„ç†æ®µè½å†…å®¹ï¼ŒåŒ…æ‹¬å¯èƒ½çš„é“¾æ¥
                    paragraph_content = {"type": "p", "content": tag.get_text(strip=True)}
                    links = [{"href": a.get("href"), "text": a.get_text(strip=True)} for a in tag.find_all("a") if a.get("href")]
                    if links:
                        paragraph_content["links"] = links
                    if stack:
                        stack[-1]["section"]["content"].append(paragraph_content)
                elif tag_name in ["ul", "ol"]:
                    # æ·»åŠ åˆ—è¡¨å†…å®¹åˆ°æœ€è¿‘çš„æ ‡é¢˜
                    list_items = [li.get_text(strip=True) for li in tag.find_all("li") if li.get_text(strip=True)]
                    if stack:
                        stack[-1]["section"]["content"].append({"type": tag_name, "content": list_items})
                elif tag_name == "img":
                    # å¤„ç†å›¾ç‰‡å†…å®¹
                    img_src = tag.get("src")
                    img_alt = tag.get("alt", "")
                    if img_src and stack:
                        stack[-1]["section"]["content"].append({"type": "img", "src": img_src, "alt": img_alt})

            return sections

        # æå–æ‰€æœ‰ç›¸å…³æ ‡ç­¾
        tags = soup.find_all(["h1", "h2", "h3", "h4", "h5", "h6", "p", "ul", "ol", "img"])
        sections = parse_sections(tags)

        # æ„å»º JSON æ•°æ®
        compressed_data = {
            "sections": sections,
            "resources": resources
        }

        # ä¿å­˜ä¸º JSON æ–‡ä»¶
        with open(output_json, "w", encoding="utf-8") as f:
            json.dump(compressed_data, f, indent=4, ensure_ascii=False)
        print(f"âœ… æˆåŠŸå°† {mhtml_file} è½¬æ¢ä¸º {output_json}")

    except Exception as e:
        print(f"âŒ è§£æ .mhtml æ–‡ä»¶å¤±è´¥: {e}")

def process_folder(input_folder, output_folder):
    """
    è¯»å–æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰ .mhtml æ–‡ä»¶ï¼Œå¹¶ç”Ÿæˆå¯¹åº”çš„ JSON æ–‡ä»¶
    """
    # ç¡®ä¿è¾“å‡ºæ–‡ä»¶å¤¹å­˜åœ¨
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # éå†è¾“å…¥æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    for filename in os.listdir(input_folder):
        if filename.endswith(".mhtml"):
            input_file = os.path.join(input_folder, filename)
            output_file = os.path.join(output_folder, f"{os.path.splitext(filename)[0]}.json")
            print(f"ğŸ“„ æ­£åœ¨å¤„ç†æ–‡ä»¶: {input_file}")
            parse_mhtml_to_json(input_file, output_file)

# ç¤ºä¾‹ï¼šå¤„ç†æ–‡ä»¶å¤¹
input_folder = "infoGetter/info"  # æ›¿æ¢ä¸ºä½ çš„è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„
output_folder = "infoGetter/output"  # æ›¿æ¢ä¸ºä½ çš„è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„
process_folder(input_folder, output_folder)
